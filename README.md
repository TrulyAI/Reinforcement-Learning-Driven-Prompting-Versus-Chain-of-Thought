Reinforcement Learning–Driven Prompting: A New Paradigm for LLM Reasoning

Large Language Models (LLMs) have revolutionized natural language processing, yet eliciting reliable reasoning from these models remains a challenge. While Chain-of-Thought (CoT) prompting encourages step-by-step solutions, its verbosity and inconsistency often hinder its effectiveness. This paper introduces Reinforcement Learning–Driven Prompting (RLDP), a novel framework that combines minimal supervised fine-tuning with reinforcement learning to optimize reasoning patterns. RLDP produces concise, accurate outputs without relying on CoT-style intermediate steps, improving performance across math, coding, and knowledge tasks. Additionally, RLDP’s outputs enhance smaller models through distillation, bridging the gap between large and resource-efficient models, and offering scalable solutions for advanced reasoning.
